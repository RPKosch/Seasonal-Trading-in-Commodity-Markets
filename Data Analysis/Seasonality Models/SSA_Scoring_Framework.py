from __future__ import annotations
import numpy as np
import pandas as pd
from dataclasses import dataclass
from typing import Optional
from dateutil.relativedelta import relativedelta
import statsmodels.api as sm  # unused, but kept for consistency
from pathlib import Path

# =========================================================
# 1. Load monthly returns (and synthetic generator if needed)
# =========================================================

def load_monthly_returns(root_dir: Path) -> dict[str, pd.Series]:
    out = {}
    for path in sorted(root_dir.glob("*_Monthly_Revenues.csv")):
        ticker = path.stem.replace("_Monthly_Revenues", "")
        df = pd.read_csv(path)
        df["date"] = pd.to_datetime(df[["year", "month"]].assign(day=1))
        df["return"] = pd.to_numeric(df["return"], errors="coerce")
        out[ticker] = df.set_index("date")["return"].sort_index()
    return out


def generate_synthetic_log_returns(n_years: int = 10,
                                   seed: int = 123) -> pd.Series:
    """
    Synthetic monthly log-return series with:
      - sinusoidal seasonal pattern (~±1%)
      - uniform noise in [-0.02, 0.02]
    Noise is generated by a hand-made LCG so that Python and R
    can produce identical series for the same seed.
    """
    n_months = 12 * n_years
    idx = pd.date_range("2000-01-01", periods=n_months, freq="MS")

    # seasonal pattern (~±1%)
    month = idx.month
    seasonal_pattern = 0.01 * np.sin(2 * np.pi * (month - 1) / 12.0)

    # custom LCG: x_{n+1} = (a*x_n) mod m, with m=2^31-1, a=16807
    m = 2**31 - 1
    a = 16807

    x = seed % m
    if x == 0:
        x = 1

    u = np.empty(n_months, dtype=float)
    for i in range(n_months):
        x = (a * x) % m
        u[i] = x / m

    # uniform noise in [-0.02, 0.02]
    noise = 0.04 * (u - 0.5)

    log_ret = seasonal_pattern + noise
    return pd.Series(log_ret, index=idx, name="log_return")


# =========================================================
# 2. EWMA volatility (RiskMetrics-style) – not used in table
# =========================================================

def ewma_sigma_next(log_returns: pd.Series,
                    lam: float = 0.97) -> float:
    """
    One-step-ahead EWMA volatility forecast sigma_{T+1}.
    """
    r = log_returns.dropna().to_numpy(dtype=float)
    if r.size == 0:
        return np.nan

    if r.size > 1:
        sigma2 = float(np.var(r, ddof=1))
    else:
        sigma2 = float(r[0] ** 2)

    for rt in r:
        sigma2 = lam * sigma2 + (1.0 - lam) * float(rt) ** 2

    return float(np.sqrt(max(sigma2, 0.0)))


# =========================================================
# 3. SSA helpers
# =========================================================

def _build_trajectory_matrix(x: np.ndarray, L: int) -> np.ndarray:
    """
    Build Hankel trajectory matrix X (L x K) from series x of length N.
    """
    N = x.size
    K = N - L + 1
    X = np.empty((L, K), dtype=float)
    for i in range(K):
        X[:, i] = x[i:i + L]
    return X


# =========================================================
# 4. Basic SSA forecast (recurrent SSA)
# =========================================================

def basic_ssa_forecast(log_returns: pd.Series,
                       L: int = 36,
                       r: int = 12) -> float:
    """
    Basic recurrent SSA one-step-ahead forecast.
    """
    x = log_returns.dropna().to_numpy(dtype=float)
    N = x.size
    if N < 2:
        return np.nan

    if L >= N:
        L = N - 1
    if L < 2:
        L = 2

    K = N - L + 1
    X = _build_trajectory_matrix(x, L)  # L x K

    # SVD of X
    U, d, Vt = np.linalg.svd(X, full_matrices=False)
    r_eff = min(r, U.shape[1])

    # Reconstruct signal matrix from first r_eff eigentriples
    X_signal = np.zeros_like(X)
    for i in range(r_eff):
        ui = U[:, i:i+1]       # L x 1
        vi = Vt[i:i+1, :].T    # K x 1
        X_signal += d[i] * (ui @ vi.T)

    # Diagonal averaging (Hankelization) -> recon[0..N-1]
    recon = np.zeros(N, dtype=float)
    counts = np.zeros(N, dtype=int)
    for i in range(L):
        for j in range(K):
            idx = i + j
            recon[idx] += X_signal[i, j]
            counts[idx] += 1
    counts[counts == 0] = 1
    recon /= counts

    # SSA recurrence coefficients (using left singular vectors U)
    if L <= 1:
        return float(recon[-1])

    nu2 = 0.0
    R_vec = np.zeros(L - 1, dtype=float)   # [a_{L-1}, ..., a_1]
    for i in range(r_eff):
        P_i = U[:, i]
        pi_i = P_i[L - 1]                  # last coordinate
        nu2 += pi_i**2
        R_vec += pi_i * P_i[:L - 1]        # first L-1 coordinates

    if abs(1.0 - nu2) < 1e-8:
        # Degenerate: fallback to AR(1) on recon
        if N < 3:
            return float(recon[-1])
        y1 = recon[1:]
        ylag = recon[:-1]
        denom = float(np.dot(ylag, ylag))
        if denom == 0.0:
            return float(recon[-1])
        phi = float(np.dot(ylag, y1) / denom)
        return float(recon[-1] * phi)

    R_vec /= (1.0 - nu2)   # [a_{L-1},...,a_1]
    a = R_vec[::-1]        # [a_1,...,a_{L-1}]

    # Tail of reconstructed series needed for recurrence
    if N > L:
        x_tail = recon[N - L + 1: N]   # length L-1
    else:
        x_tail = recon.copy()
        if x_tail.size < (L - 1):
            pad = np.full((L - 1 - x_tail.size,), x_tail[0], dtype=float)
            x_tail = np.concatenate([pad, x_tail])

    x_tail_rev = x_tail[::-1]          # x_N, x_{N-1}, ..., x_{N-L+2}
    forecast = float(np.dot(a, x_tail_rev))  # \hat x_{N+1}
    return forecast


# =========================================================
# 5. Scaling experiment: SSA forecast only
# =========================================================

def run_ssa_scaling_experiment(
    c: float = 2.0,
    use_synthetic: bool = False,
    n_years: int = 10,
    seed: int = 123,
    ticker: str = "CC",
    start: str = "2005-01-01",
    end: str = "2014-12-01",
) -> pd.DataFrame:
    """
    Scaling experiment for a single contract (default: CC, 2005–2014) using SSA.

    - If use_synthetic is False, uses real simple returns from CSV.
    - If use_synthetic is True, uses a synthetic log-return series.
    - Compares SSA one-step forecast for c = 1 vs c = c.
    """
    if use_synthetic:
        returns_base = generate_synthetic_log_returns(n_years=n_years, seed=seed)
    else:
        base = Path().resolve().parent.parent / "Complete Data"
        returns = load_monthly_returns(base / "All_Monthly_Log_Return_Data")
        returns_base = returns[ticker].loc[start:end]

    returns_scaled = c * returns_base

    N = len(returns_base)
    last_month = returns_base.index[-1].month
    target_month = 1 if last_month == 12 else last_month + 1
    forecast_month = returns_base.index[-1] + relativedelta(months=1)

    f_ssa_base   = basic_ssa_forecast(returns_base,   L=36, r=12)
    f_ssa_scaled = basic_ssa_forecast(returns_scaled, L=36, r=12)

    rows = [{
        "Model": "SSA",
        "Statistic": "forecast",
        "Value c=1": f_ssa_base,
        f"Value c={c:g}": f_ssa_scaled,
    }]

    result = pd.DataFrame(rows)

    pd.set_option("display.float_format", lambda x: f"{x: .6g}")

    print(f"\n=== SSA scaling experiment (ticker {ticker}, c = {c}) ===\n")
    print(f"Series length: {N} months")
    print(f"Target calendar month (1=Jan,...,12=Dec): {target_month}\n")
    print(result.to_string(index=False))

    return result


# =========================================================
# 6. Run when executed as script
# =========================================================

if __name__ == "__main__":
    run_ssa_scaling_experiment(c=2.0, use_synthetic=False)
