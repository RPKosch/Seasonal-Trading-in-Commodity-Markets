from __future__ import annotations
import numpy as np
import pandas as pd
from dataclasses import dataclass  # kept for consistency, not used
from typing import Optional         # kept for consistency, not used
from dateutil.relativedelta import relativedelta
import statsmodels.api as sm       # kept for consistency, not used
from pathlib import Path

# =========================================================
# 1. Load monthly returns (and synthetic generator if needed)
# =========================================================

def load_monthly_returns(root_dir: Path) -> dict[str, pd.Series]:
    out = {}
    for path in sorted(root_dir.glob("*_Monthly_Revenues.csv")):
        ticker = path.stem.replace("_Monthly_Revenues", "")
        df = pd.read_csv(path)
        df["date"] = pd.to_datetime(df[["year", "month"]].assign(day=1))
        df["return"] = pd.to_numeric(df["return"], errors="coerce")
        out[ticker] = df.set_index("date")["return"].sort_index()
    return out


def generate_synthetic_log_returns(n_years: int = 10,
                                   seed: int = 123) -> pd.Series:
    """
    Synthetic monthly log-return series with:
      - sinusoidal seasonal pattern (~±1%)
      - uniform noise in [-0.02, 0.02]

    Noise is generated by a hand-made LCG so that Python and R
    can produce identical series for the same seed.
    """
    n_months = 12 * n_years
    idx = pd.date_range("2000-01-01", periods=n_months, freq="MS")

    # seasonal pattern (~±1%)
    month = idx.month
    seasonal_pattern = 0.01 * np.sin(2 * np.pi * (month - 1) / 12.0)

    # custom LCG: x_{n+1} = (a*x_n) mod m, with m=2^31-1, a=16807
    m = 2**31 - 1
    a = 16807

    x = seed % m
    if x == 0:
        x = 1

    u = np.empty(n_months, dtype=float)
    for i in range(n_months):
        x = (a * x) % m
        u[i] = x / m

    # uniform noise in [-0.02, 0.02]
    noise = 0.04 * (u - 0.5)

    log_ret = seasonal_pattern + noise
    return pd.Series(log_ret, index=idx, name="log_return")


# =========================================================
# 2. EWMA volatility (RiskMetrics-style) – not used in table
# =========================================================

def ewma_sigma_next(log_returns: pd.Series,
                    lam: float = 0.97) -> float:
    """
    One-step-ahead EWMA volatility forecast sigma_{T+1}.
    """
    r = log_returns.dropna().to_numpy(dtype=float)
    if r.size == 0:
        return np.nan

    if r.size > 1:
        sigma2 = float(np.var(r, ddof=1))
    else:
        sigma2 = float(r[0] ** 2)

    for rt in r:
        sigma2 = lam * sigma2 + (1.0 - lam) * float(rt) ** 2

    return float(np.sqrt(max(sigma2, 0.0)))


# =========================================================
# 3. RLSSA: Robust L1 Singular Spectrum Analysis (Hawkins AL1)
# =========================================================

def _build_trajectory_matrix(x: np.ndarray, L: int) -> np.ndarray:
    """
    Build Hankel trajectory matrix X (L x K) from series x of length N.
    """
    N = x.size
    K = N - L + 1
    X = np.empty((L, K), dtype=float)
    for i in range(K):
        X[:, i] = x[i:i + L]
    return X


def _weighted_median(values: np.ndarray, weights: np.ndarray) -> float:
    """
    Weighted median mirroring matrixStats::weightedMedian(x, w,
    na.rm = TRUE, interpolate = FALSE, ties = "weighted").
    """
    values = np.asarray(values, dtype=float)
    weights = np.asarray(weights, dtype=float)

    # Drop NA in x or w (na.rm = TRUE)
    mask = ~np.isnan(values) & ~np.isnan(weights)
    if not np.any(mask):
        return 0.0

    values = values[mask]
    weights = weights[mask]

    if values.size == 0:
        return 0.0

    # Negative weights treated as zero
    weights = np.where(weights > 0.0, weights, 0.0)

    total_w = float(np.sum(weights))
    if total_w == 0.0:
        return 0.0

    # Special case: any infinite weights => treat all Inf weights equal, others 0
    if np.any(np.isinf(weights)):
        inf_mask = np.isinf(weights)
        vals_inf = values[inf_mask]
        if vals_inf.size == 0:
            return 0.0
        return float(np.median(vals_inf))

    # Sort by values
    order = np.argsort(values)
    v_sorted = values[order]
    w_sorted = weights[order]

    # Collapse to unique x's with summed weights
    uniq_vals, inv = np.unique(v_sorted, return_inverse=True)
    uniq_w = np.zeros_like(uniq_vals, dtype=float)
    for idx, g in enumerate(inv):
        uniq_w[g] += w_sorted[idx]

    cum_w = np.cumsum(uniq_w)
    S = float(cum_w[-1])
    half = 0.5 * S

    w_less = np.concatenate(([0.0], cum_w[:-1]))
    w_greater = S - cum_w

    cand_mask = (w_less <= half) & (w_greater <= half)
    cand_idx = np.where(cand_mask)[0]

    if cand_idx.size == 0:
        k = int(np.searchsorted(cum_w, half, side="left"))
        return float(uniq_vals[k])

    if cand_idx.size == 1:
        return float(uniq_vals[cand_idx[0]])

    # Two candidates: ties = "weighted"
    i_low, i_high = int(cand_idx[0]), int(cand_idx[1])
    w_le_low = cum_w[i_low]
    if i_high > 0:
        w_ge_high = S - cum_w[i_high - 1]
    else:
        w_ge_high = S

    num = w_le_low * uniq_vals[i_low] + w_ge_high * uniq_vals[i_high]
    den = w_le_low + w_ge_high
    if den == 0.0:
        return float(0.5 * (uniq_vals[i_low] + uniq_vals[i_high]))
    return float(num / den)


def _l1_reg_coef(x: np.ndarray, a: np.ndarray, eps: float) -> float:
    """
    L1RegCoef from R robustSvd: one-dimensional L1 regression coefficient.
    """
    x = np.asarray(x, dtype=float)
    a = np.asarray(a, dtype=float)

    keep = (np.abs(a) > eps) & (~np.isnan(x))
    if not np.any(keep):
        return 0.0

    x_keep = x[keep]
    a_keep = a[keep]
    z = x_keep / a_keep
    w = np.abs(a_keep)

    return _weighted_median(z, w)


def _l1_eigen(x: np.ndarray, a: np.ndarray, b: np.ndarray, eps: float) -> float:
    """
    L1Eigen from R robustSvd.
    """
    x_vec = np.asarray(x, dtype=float).reshape(-1)
    ab = np.outer(a, b).reshape(-1)

    keep = (np.abs(ab) > eps) & (~np.isnan(x_vec))
    if not np.any(keep):
        return 0.0

    xk = x_vec[keep]
    abk = ab[keep]
    z = xk / abk
    w = np.abs(abk)

    return _weighted_median(z, w)


def robust_svd(X: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Python port of the R robustSvd() function (Hawkins AL1 algorithm).

    Returns (u, d, v) such that X ≈ u diag(d) v^T.
    """
    X = np.asarray(X, dtype=float)
    m, n = X.shape
    eps = np.finfo(float).eps

    svdu = np.empty((m, n), dtype=float)
    svdv = np.empty((n, n), dtype=float)
    svdd = np.empty(n, dtype=float)

    X_resid = X.copy()

    for k in range(n):
        # initial ak: median of abs(x) along rows
        ak = np.nanmedian(np.abs(X_resid), axis=1)
        converged = False
        while not converged:
            akprev = ak.copy()

            # c: apply L1RegCoef over columns
            c = np.empty(n, dtype=float)
            for j in range(n):
                c[j] = _l1_reg_coef(X_resid[:, j], ak, eps)

            norm_c = float(np.sqrt(np.sum(c**2)))
            if norm_c == 0.0:
                bk = np.zeros(n, dtype=float)
            else:
                bk = c / norm_c

            # d: apply L1RegCoef over rows
            d = np.empty(m, dtype=float)
            for i in range(m):
                d[i] = _l1_reg_coef(X_resid[i, :], bk, eps)

            norm_d = float(np.sqrt(np.sum(d**2)))
            if norm_d == 0.0:
                ak = np.zeros(m, dtype=float)
            else:
                ak = d / norm_d

            diff = ak - akprev
            if float(np.sum(diff**2)) < 1e-10:
                converged = True

        eigenk = _l1_eigen(X_resid, ak, bk, eps)

        # Deflate the residual X
        X_resid = X_resid - eigenk * np.outer(ak, bk)

        # Store eigen triple
        svdu[:, k] = ak
        svdv[:, k] = bk
        svdd[k] = eigenk

    return svdu, svdd, svdv


def rlssa_forecast(log_returns: pd.Series,
                   L: int = 36,
                   r: int = 12) -> float:
    """
    One-step-ahead RLSSA forecast.

    (i) Robust L1 SVD -> robust low-rank signal matrix S
    (ii) Hankelization -> recon
    (iii) Classical SSA LRR coefficients on S + recurrent forecast
    """
    x = log_returns.dropna().to_numpy(dtype=float)
    N = x.size
    if N < 2:
        return np.nan

    if L >= N:
        L = N - 1
    if L < 2:
        L = 2

    K = N - L + 1
    X = _build_trajectory_matrix(x, L)  # L x K

    # Stage (i): robust SVD
    try:
        U_r, d_r, V_r = robust_svd(X)
    except Exception:
        # fallback: classical SVD
        U_r, d_r, Vt_r = np.linalg.svd(X, full_matrices=False)
        V_r = Vt_r.T

    r_eff = min(r, U_r.shape[1])

    # Robust low-rank signal matrix S
    S = np.zeros_like(X)
    for i in range(r_eff):
        ui = U_r[:, i:i+1]   # L x 1
        vi = V_r[:, i:i+1]   # K x 1
        S += d_r[i] * (ui @ vi.T)

    # Hankelization -> recon (robust fitted series)
    recon = np.zeros(N, dtype=float)
    counts = np.zeros(N, dtype=int)
    for i in range(L):
        for j in range(K):
            idx = i + j
            recon[idx] += S[i, j]
            counts[idx] += 1
    counts[counts == 0] = 1
    recon /= counts

    # Stage (ii): classical SVD on S to get LRR coefficients
    U2, d2, Vt2 = np.linalg.svd(S, full_matrices=False)
    r_eff2 = min(r, U2.shape[1])

    if L <= 1:
        return float(recon[-1])

    nu2 = 0.0
    R_vec = np.zeros(L - 1, dtype=float)   # [a_{L-1},...,a_1]
    for j in range(r_eff2):
        P_j = U2[:L-1, j]
        phi_j = U2[L-1, j]
        nu2 += phi_j**2
        R_vec += phi_j * P_j

    if abs(1.0 - nu2) < 1e-8:
        # fallback AR(1) on recon
        if N < 3:
            return float(recon[-1])
        y1 = recon[1:]
        ylag = recon[:-1]
        denom = float(np.dot(ylag, ylag))
        if denom == 0.0:
            return float(recon[-1])
        phi = float(np.dot(ylag, y1) / denom)
        return float(recon[-1] * phi)

    R_vec /= (1.0 - nu2)
    a = R_vec[::-1]   # [a_1,...,a_{L-1}]

    # Stage (iii): 1-step recurrent forecast
    if N > L:
        x_tail = recon[N - L + 1: N]   # length L-1
    else:
        x_tail = recon.copy()
        if x_tail.size < (L - 1):
            pad = np.full((L - 1 - x_tail.size,), x_tail[0], dtype=float)
            x_tail = np.concatenate([pad, x_tail])
    x_tail_rev = x_tail[::-1]
    forecast = float(np.dot(a, x_tail_rev))
    return forecast


# =========================================================
# 4. Scaling experiment: RLSSA forecast only
# =========================================================

def run_rlssa_scaling_experiment(
    c: float = 2.0,
    use_synthetic: bool = False,
    n_years: int = 10,
    seed: int = 123,
    ticker: str = "CC",
    start: str = "2005-01-01",
    end: str = "2014-12-01",
) -> pd.DataFrame:
    """
    Scaling experiment for a single contract (default: CC, 2005–2014) using RLSSA.

    - If use_synthetic is False, uses real simple returns from CSV.
    - If use_synthetic is True, uses a synthetic log-return series.
    - Compares RLSSA one-step forecast for c = 1 vs c = c.
    """
    if use_synthetic:
        returns_base = generate_synthetic_log_returns(n_years=n_years, seed=seed)
    else:
        base = Path().resolve().parent.parent / "Complete Data"
        returns = load_monthly_returns(base / "All_Monthly_Log_Return_Data")
        returns_base = returns[ticker].loc[start:end]

    returns_scaled = c * returns_base

    N = len(returns_base)
    last_month = returns_base.index[-1].month
    target_month = 1 if last_month == 12 else last_month + 1
    forecast_month = returns_base.index[-1] + relativedelta(months=1)

    f_rls_base   = rlssa_forecast(returns_base,   L=36, r=12)
    f_rls_scaled = rlssa_forecast(returns_scaled, L=36, r=12)

    rows = [{
        "Model": "RLSSA",
        "Statistic": "forecast",
        "Value c=1": f_rls_base,
        f"Value c={c:g}": f_rls_scaled,
    }]

    result = pd.DataFrame(rows)

    pd.set_option("display.float_format", lambda x: f"{x: .6g}")

    print(f"\n=== RLSSA scaling experiment (ticker {ticker}, c = {c}) ===\n")
    print(f"Series length: {N} months")
    print(f"Target calendar month (1=Jan,...,12=Dec): {target_month}\n")
    print(result.to_string(index=False))

    return result


# =========================================================
# 5. Run when executed as script
# =========================================================

if __name__ == "__main__":
    run_rlssa_scaling_experiment(c=2.0, use_synthetic=False)
